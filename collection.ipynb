{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from mediapipe.python.solutions import holistic\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing=mp.solutions.drawing_utils   #holistic model\n",
    "mp_holistic=mp.solutions.holistic       #drawing utilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image,model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  #color conversion BGR to RGB\n",
    "    image.flags.writeable = False                   #Image is no longer writeable\n",
    "    results = model.process(image)                  # make prediction\n",
    "    image.flags.writeable = True                    #image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  #color conversion again RGB to BGR\n",
    "    return image,results\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x,res.y,res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose,face,lh,rh])\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)  # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)  # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) #Draw right hand connections\n",
    "\n",
    "def draw_style_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                              mp_drawing.DrawingSpec(color=(175,13,13), thickness=1, circle_radius=1),   #color dot\n",
    "                              mp_drawing.DrawingSpec(color=(0,0,0), thickness=1, circle_radius=1)    #color line\n",
    "                              )\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(178,16,16), thickness=2, circle_radius=4),   #color dot\n",
    "                              mp_drawing.DrawingSpec(color=(0,0,0), thickness=2, circle_radius=2)    #color line\n",
    "                              )\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(0,0,0), thickness=2, circle_radius=1),   #color dot\n",
    "                              mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=2)    #color line\n",
    "                              )\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=1),   #color dot\n",
    "                              mp_drawing.DrawingSpec(color=(0,0,0), thickness=2, circle_radius=2)    #color line\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "  while cap.isOpened():\n",
    "    # Read feed\n",
    "    ret,frame=cap.read()\n",
    "    #make detections\n",
    "    image, results= mediapipe_detection(frame, holistic)\n",
    "    print(results)\n",
    "\n",
    "    # Draw landmarks\n",
    "    # draw_landmarks(image, results)  #default landmarks in face hand \n",
    "\n",
    "    draw_style_landmarks(image, results) #customized landmarks in face and hand\n",
    "    #show to screen\n",
    "    cv2.putText(image,\"Starting collecting\", (120,200), #display message in screen at position x=120 and y=200\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,225,0), 4, cv2.LINE_AA) \n",
    "    # Flip the image horizontally\n",
    "    image = cv2.flip(image, 1)\n",
    "    cv2.imshow('OPENCV FEED',image)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "      break\n",
    "  cap.release()\n",
    "  cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('D:\\Hand-Gesture-Recognition\\Frame_Data')\n",
    "IMAGES_PATH=os.path.join('D:\\Hand-Gesture-Recognition\\Frame_COLLECTION')\n",
    "actions=np.array(['Aausadi','Ambulance','Bathroom','Be Careful','Bleeding','Call','Dhanebad','Doctor','Dont Understand','Eklopan',\n",
    "                  'Emergency','Firstaid','Good Morning','Happy','Heart_attack','Hello','Help','Hospital','Name','Need','Nice To Meet You',\n",
    "                  'Oxygen','Pain','Please','Police','Relax','Sign','Slowly','Sorry','What','Yes','You'])\n",
    "\n",
    "#thirty videos worth of data\n",
    "no_sequences = 50\n",
    "\n",
    "#videos are going to be 60 frames in length\n",
    "sequence_length = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "            os.makedirs(os.path.join(IMAGES_PATH, action, str(sequence)))\n",
    "       \n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "#setup mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "  \n",
    "# loop through actions\n",
    "  for action in actions:\n",
    "        # loop through sequences\n",
    "        for sequence in range(no_sequences):\n",
    "            # loop through number of sequences length\n",
    "            for frame_num in range(sequence_length):\n",
    "        # Read feed\n",
    "                ret,frame=cap.read()\n",
    "                #make detections\n",
    "                image, results= mediapipe_detection(frame, holistic)\n",
    "                # print(results)\n",
    "\n",
    "                # Draw landmarks\n",
    "                # draw_landmarks(image, results)  #default landmarks in face hand \n",
    "                draw_style_landmarks(image, results) #customized landmarks in face and hand\n",
    "                \n",
    "\n",
    "                if frame_num == 0:\n",
    "                    cv2.putText(image,\"Starting collecting\", (120,200), #display message in screen at position x=120 and y=200\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,225,0), 4, cv2.LINE_AA) #using font style 1=size (0,255,0)=color and 4=line width\n",
    "                    cv2.putText(image,'Collecting frames for {}'.format(action,sequence),(15,12), #same\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255),1, cv2.LINE_AA) #same\n",
    "                    # image = cv2.flip(image, 1)\n",
    "                    cv2.imshow('OPENCV FEED',image)\n",
    "                    cv2.waitKey(2000) #break for each video\n",
    "                else:\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action,sequence),(15,12), #same for if frame_num!=0\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255),1,cv2.LINE_AA)\n",
    "                    # image = cv2.flip(image, 1)\n",
    "                    cv2.imshow('OPENCV FEED',image)\n",
    "                    \n",
    "\n",
    "                #exporting keypoints in respective folders\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                np.save(npy_path,keypoints)\n",
    "\n",
    "\n",
    "                \n",
    "                # Save frames as jpg in respective folders\n",
    "                img_path = os.path.join(IMAGES_PATH, action, str(sequence), str(frame_num) + '.jpg')\n",
    "                cv2.imwrite(img_path, image)\n",
    "                #show to screen\n",
    "                # print(\"frame_num:\", frame_num)\n",
    "\n",
    "\n",
    "                key = cv2.waitKey(10)\n",
    "                if key == ord('q') or key == ord('Q'):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    raise SystemExit(\"Program terminated by user\")  # Raise SystemExit to exit gracefully\n",
    "\n",
    "                # if cv2.waitKey(10) & 0xFF==ord('q') or 0xFF==ord('Q'):  #for quiting program\n",
    "                #     break\n",
    "                \n",
    "                \n",
    "  cap.release()\n",
    "  cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
